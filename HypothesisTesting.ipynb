{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FacebookTime        Day           Date  Year\n",
      "0        6:57pm   Saturday     October 28  2020\n",
      "1        1:12pm     Sunday    October 25   2020\n",
      "2        4:10pm    Tuesday     October 13  2020\n",
      "3        5:34pm  Wednesday   September 30  2020\n",
      "4        6:34pm     Monday   September 28  2020\n",
      "..          ...        ...            ...   ...\n",
      "69       7:27pm   Saturday      August 03  2019\n",
      "70       1:16am   Thursday        June 18  2020\n",
      "71      12:03am    Tuesday        June 11  2019\n",
      "72       4:51am    Tuesday        June 04  2019\n",
      "73       4:51am    Tuesday        June 04  2019\n",
      "\n",
      "[74 rows x 4 columns]\n",
      "    InstagramTime        Day           Date  Year\n",
      "0          7:30pm  Wednesday   September 30  2020\n",
      "1          8:28pm   Saturday   September 26  2020\n",
      "2          2:05pm   Saturday   September 12  2020\n",
      "3          9:56pm     Friday   September 11  2020\n",
      "4          6:44pm     Friday   September 11  2020\n",
      "..            ...        ...            ...   ...\n",
      "70         6:21pm   Saturday      August 03  2019\n",
      "71         1:29am   Thursday        June 18  2020\n",
      "72        12:03am    Tuesday        June 11  2019\n",
      "73         4:51am    Tuesday        June 04  2019\n",
      "74         4:51am    Tuesday        June 04  2019\n",
      "\n",
      "[75 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## read csv to dataframe\n",
    "fb_df = pd.read_csv(\"fb.csv\")\n",
    "insta_df = pd.read_csv(\"insta.csv\")\n",
    "print(fb_df)\n",
    "print(insta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 25, 15, 18, 20, 24, 24]\n"
     ]
    }
   ],
   "source": [
    "#1. Explore the frequency by days\n",
    "\n",
    "fb_days = fb_df.groupby(\"Day\")\n",
    "insta_days = insta_df.groupby(\"Day\")\n",
    "days = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
    "day_df1 = pd.DataFrame()\n",
    "day_df2 = pd.DataFrame()\n",
    "# calculate frequency of number of times online for fb data\n",
    "day_freq = []\n",
    "for day in days:\n",
    "    day_df1 = fb_days.get_group(day)[\"Day\"]\n",
    "    day_df2 = insta_days.get_group(day)[\"Day\"]\n",
    "    day_df1 = day_df1.append(day_df2,ignore_index=True)\n",
    "    day_freq.append(len(day_df1))\n",
    "    #print(day_freq)\n",
    "print(day_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekdays frequency: 20.2 Weekend Frequency: 24.0\n"
     ]
    }
   ],
   "source": [
    "## Calculate average number of times I am online on social media during weekend and weekday\n",
    "sumweek = 0\n",
    "for i in range(0,5):\n",
    "    sumweek +=day_freq[i]\n",
    "sumweekend = day_freq[5] + day_freq[6]\n",
    "\n",
    "print(\"Weekdays frequency:\",sumweek/5,\"Weekend Frequency:\",sumweekend/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis question: Am I more often on social media during the weekend than weekday?\n",
    "\n",
    "Step 1:(Stating hypothesis)   \n",
    "$H_o : \\mu_{weekday} = \\mu_{weekend}$  \n",
    "$H_1 : \\mu_{weekend} > \\mu_{weekday}$  \n",
    "\n",
    "Step 2:(Level of Significance)  \n",
    "For testing purpose, I will just use a level of significance of 0.05\n",
    "\n",
    "Step 3:(Test determined)  \n",
    "This is a one tailed test two independent test  \n",
    "df =  5 + 2-2 = 5    \n",
    "t = $\\frac{x_1 + x_2}{\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}$  \n",
    "t-value = 2.015  (If t computed is larger than 2.015, reject null hypothesis.Else do not.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    23\n",
      "1    25\n",
      "2    15\n",
      "3    18\n",
      "4    20\n",
      "dtype: int64\n",
      "0    24\n",
      "1    24\n",
      "dtype: int64\n",
      "t-computed: -1.2815623994965906 p-value: 0.128103804904969\n",
      "Fail to reject H0, p-value: 0.128103804904969\n"
     ]
    }
   ],
   "source": [
    "##Step 4:\n",
    "\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "alpha = 0.05\n",
    "weekday_ser = pd.Series(day_freq[0:5])\n",
    "print(weekday_ser)\n",
    "weekend_ser = pd.Series(day_freq[5:7])\n",
    "print(weekend_ser)\n",
    "\n",
    "\n",
    "# ttest_ind performs a two-tailed test\n",
    "t_computed, p_value = stats.ttest_ind(weekday_ser,weekend_ser)\n",
    "print(\"t-computed:\", t_computed, \"p-value:\", p_value/2)\n",
    "if p_value/2 < alpha: \n",
    "    print(\"Reject H0, p-value:\", p_value/2)\n",
    "else:\n",
    "    print(\"Fail to reject H0, p-value:\", p_value/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, I did not appear to be more active online during the weekday or weekends. t-computed is smaller than 2.105 and the p-value is larger than 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLEAN DATA FOR TIME\n",
    "\n",
    "# e.g: if 1:00am, 2:00am,3:00am,4:00am,5:00am or 6:00am will be hard to classify whether it is before or after 5:00pm\n",
    "# so in this case, i think its best to disregard the data\n",
    "# This anamolies exist because i suspect of the time difference between US and Malaysia. The data obtained contains the \n",
    "# day, month, year where I still have not come to the US. So, the time change may be why I am online during such odd hours\n",
    "\n",
    "# clean facebook first\n",
    "i =0 \n",
    "for index, row in fb_df.iterrows():\n",
    "    strtime = row['FacebookTime']\n",
    "    if strtime.find(\"am\")!= -1:\n",
    "        if(int(strtime.split(':')[0]) < 7):\n",
    "            fb_df.drop(index, inplace=True)\n",
    "        elif(int(strtime.split(':')[0]) > 11):\n",
    "            fb_df.drop(index, inplace=True)\n",
    "\n",
    "for index, row in insta_df.iterrows():\n",
    "    strtime = row[0]\n",
    "    if strtime.find(\"am\")!= -1:\n",
    "        if(int(strtime.split(':')[0]) < 7):\n",
    "            insta_df.drop(index, inplace=True)\n",
    "        elif(int(strtime.split(':')[0]) > 11):\n",
    "            insta_df.drop(index, inplace=True)\n",
    "\n",
    "fb_df.to_csv(\"fbcleaned.csv\",index=False)\n",
    "insta_df.to_csv(\"instacleaned.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before 5:00pm: [5, 7, 3, 10, 6, 5, 1] After 5:00pm: [3, 6, 9, 4, 2, 2, 4]\n",
      "dict_keys(['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday'])\n",
      "Before 5:00pm: [5, 3, 8, 6, 6, 7, 5] After 5:00pm: [6, 4, 4, 2, 2, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "## Group the time before and after 5:00pm for facebook\n",
    "fb_am = 0\n",
    "fb_pm = 0\n",
    "fb_amser =[]\n",
    "fb_pmser =[]\n",
    "days_week = []\n",
    "\n",
    "fb_days = fb_df.groupby('Day')\n",
    "days = fb_days.groups.keys()\n",
    "\n",
    "#group am and pm\n",
    "for day in days:\n",
    "    idf = fb_days.get_group(day)\n",
    "    fb_am =0\n",
    "    fb_pm =0\n",
    "    for fbtime in idf.iloc[:,0]:\n",
    "        if(fbtime.find(\"am\")!= -1):\n",
    "            fb_am +=1\n",
    "        elif(fbtime.find(\"pm\")!= -1): #it can be before 5:00pm like 1:00,2:00,3:00pm etc. so we have to compare\n",
    "            if(fbtime[1] < \"5\"):\n",
    "                fb_am +=1\n",
    "            else:\n",
    "                fb_pm +=1\n",
    "    fb_amser.append(fb_am)\n",
    "    fb_pmser.append(fb_pm)\n",
    "    days_week.append(day)\n",
    "            \n",
    "print(\"Before 5:00pm:\",fb_amser,\"After 5:00pm:\",fb_pmser)\n",
    "\n",
    "## Group for time before and after 5:00pm for Instagram\n",
    "\n",
    "insta_days = insta_df.groupby('Day')\n",
    "days = insta_days.groups.keys()\n",
    "print(days)\n",
    "insta_am = 0\n",
    "insta_pm = 0\n",
    "insta_amser =[]\n",
    "insta_pmser = []\n",
    "\n",
    "#group am and pm\n",
    "j= 0\n",
    "for day in days:\n",
    "    idf = insta_days.get_group(day)\n",
    "    insta_am = 0\n",
    "    insta_pm =0\n",
    "    for instatime in idf.iloc[:,0]:\n",
    "        if(instatime.find(\"am\")!= -1):\n",
    "            insta_am +=1\n",
    "        elif(instatime.find(\"pm\")!= -1): #it can be before 5:00pm like 1:00,2:00,3:00pm etc. so we have to compare\n",
    "            if(instatime[1] < \"5\"):\n",
    "                insta_am+=1\n",
    "            else:\n",
    "                insta_pm +=1\n",
    "                \n",
    "    insta_amser.append(insta_am)\n",
    "    insta_pmser.append(insta_pm)\n",
    "        \n",
    "\n",
    "print(\"Before 5:00pm:\",insta_amser,\"After 5:00pm:\",insta_pmser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before 5: [10 10 11 16 12 12  6] After 5: [ 9 10 13  6  4  7  9]\n"
     ]
    }
   ],
   "source": [
    "## Total for both social media before 5:00pm and after 5:00pm \n",
    "\n",
    "before_5 = np.array(fb_amser) + np.array(insta_amser)\n",
    "after_5 = np.array(fb_pmser) + np.array(insta_pmser)\n",
    "print(\"Before 5:\",before_5,\"After 5:\",after_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis question: Am I more active online on Social media during the day(before 5:00pm) than night(after 5:00pm)\n",
    "\n",
    "Step 1:(Stating hypothesis and null hypothesis)  \n",
    "$H_o: \\mu_{before5} = \\mu_{after5}$  \n",
    "$H_o : \\mu_{before5} > \\mu_{after5}$  \n",
    "\n",
    "Step 2:(Choosing significance level)  \n",
    "I will choose a significance level of 0.10\n",
    "\n",
    "Step 3:(Identifying type of test to use)  \n",
    "We will use a two sample independent test but one tailed because a direction is present  \n",
    "df = 7 + 7 -2  \n",
    "t- value = 1.385  \n",
    "t = $\\frac{x_1 + x_2}{\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}$  \n",
    "If t-computed is larger than t-value, we reject the null hypothesis; else do not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-computed: 1.7131723058681207 p-value: 0.05618635306216984\n",
      "Reject H0, p-value: 0.05618635306216984\n"
     ]
    }
   ],
   "source": [
    "## Step 4:\n",
    "alpha = 0.10\n",
    "# ttest_ind performs a two-tailed test\n",
    "t_computed, p_value = stats.ttest_ind(before_5,after_5)\n",
    "print(\"t-computed:\", t_computed, \"p-value:\", p_value/2)\n",
    "if p_value/2 < alpha: \n",
    "    print(\"Reject H0, p-value:\", p_value/2)\n",
    "else:\n",
    "    print(\"Fail to reject H0, p-value:\", p_value/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p value is smaller than 0.10, and the t-computed is larger than 1.385, we reject the null hypothesis. Therefore, I am more active on social media during the day than night"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing: Is the news sentiment more positive when I am offline vs when I am online?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Day         Date  News Sentiment Online Status\n",
      "0  Wednesday   December 9       -0.126400           Yes\n",
      "1   Thursday  December 10       -0.016700            No\n",
      "2     Friday  December 11        0.356700            No\n",
      "3   Saturday  December 12        0.018300           Yes\n",
      "4     Sunday  December 13        0.017800           Yes\n",
      "5     Monday  December 14        0.102789            No\n",
      "6    Tuesday  December 15       -0.227500           Yes\n",
      "7  Wednesday  December 16       -0.349520           Yes\n"
     ]
    }
   ],
   "source": [
    "news_df = pd.read_csv(\"news.csv\")\n",
    "print(news_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1:(Stating hypothesis)   \n",
    "$H_o : \\mu_{online} = \\mu_{offline}$  \n",
    "$H_1 : \\mu_{offline} > \\mu_{online}$  \n",
    "\n",
    "Step 2:(Level of Significance)  \n",
    "For testing purpose, I will just use a level of significance of 0.05\n",
    "\n",
    "Step 3:(Test determined)  \n",
    "This is a two tailed test two independent test  \n",
    "df =  5 + 3-2 = 6  \n",
    "t = $\\frac{x_1 + x_2}{\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}$  \n",
    "t-value = 1.943 (If t computed is larger than 1.943, reject null hypothesis.Else do not.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -0.12640\n",
      "3    0.01830\n",
      "4    0.01780\n",
      "6   -0.22750\n",
      "7   -0.34952\n",
      "Name: News Sentiment, dtype: float64\n",
      "1   -0.016700\n",
      "2    0.356700\n",
      "5    0.102789\n",
      "Name: News Sentiment, dtype: float64\n",
      "t-computed: 2.258591336455928 p-value: 0.03233658858187175\n",
      "Reject H0, p-value: 0.03233658858187175\n"
     ]
    }
   ],
   "source": [
    "# Grouping data by offline or online\n",
    "\n",
    "off_on = news_df.groupby(\"Online Status\")\n",
    "online = off_on.get_group(\"Yes\")\n",
    "online_sent = online[\"News Sentiment\"]\n",
    "print(online_sent)\n",
    "offline  =off_on.get_group(\"No\")\n",
    "offline_sent = offline[\"News Sentiment\"]\n",
    "print(offline_sent)\n",
    "\n",
    "## carying out t test\n",
    "## Step 4:\n",
    "alpha = 0.05\n",
    "# ttest_ind performs a one-tailed test\n",
    "t_computed, p_value = stats.ttest_ind(offline_sent,online_sent)\n",
    "print(\"t-computed:\", t_computed, \"p-value:\", p_value/2)\n",
    "if p_value/2 < alpha: \n",
    "    print(\"Reject H0, p-value:\", p_value/2)\n",
    "else:\n",
    "    print(\"Fail to reject H0, p-value:\", p_value/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Based on my findings, it seems that the news sentiment is generally more positive when I am offline compare to when I am online. This is an interesting finding that can help provide some support as to when I am on social media  The t value computed was larger than 1.943 and p value was smaller than 0.05, so reject null hypothesis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
