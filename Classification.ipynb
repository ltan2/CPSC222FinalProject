{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing and cleaning data up for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FacebookTime        Day           Date  Year\n",
      "0        6:57pm   Saturday     October 28  2020\n",
      "1        1:12pm     Sunday    October 25   2020\n",
      "2        4:10pm    Tuesday     October 13  2020\n",
      "3        5:34pm  Wednesday   September 30  2020\n",
      "4        6:34pm     Monday   September 28  2020\n",
      "..          ...        ...            ...   ...\n",
      "62      11:10am     Monday   September 30  2019\n",
      "63       8:27am     Monday   September 23  2029\n",
      "64       1:10pm   Thursday   September 19  2019\n",
      "65       3:30pm     Monday      August 19  2019\n",
      "66       7:27pm   Saturday      August 03  2019\n",
      "\n",
      "[67 rows x 4 columns]\n",
      "    InstagramTime        Day           Date  Year\n",
      "0          7:30pm  Wednesday   September 30  2020\n",
      "1          8:28pm   Saturday   September 26  2020\n",
      "2          2:05pm   Saturday   September 12  2020\n",
      "3          9:56pm     Friday   September 11  2020\n",
      "4          6:44pm     Friday   September 11  2020\n",
      "..            ...        ...            ...   ...\n",
      "63         8:46pm     Friday     October 18  2019\n",
      "64        11:10am    Tuesday     October 01  2019\n",
      "65         1:10pm   Thursday   September 19  2019\n",
      "66         3:30pm     Monday      August 19  2019\n",
      "67         6:21pm   Saturday      August 03  2019\n",
      "\n",
      "[68 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## read csv to dataframe\n",
    "fb_df = pd.read_csv(\"fbcleaned.csv\")\n",
    "insta_df = pd.read_csv(\"instacleaned.csv\")\n",
    "print(fb_df)\n",
    "print(insta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Time        Day           Date  Year  Social Media\n",
      "0     after5   Saturday     October 28  2020           0.0\n",
      "1    before5     Sunday    October 25   2020           0.0\n",
      "2    before5    Tuesday     October 13  2020           0.0\n",
      "3     after5  Wednesday   September 30  2020           0.0\n",
      "4     after5     Monday   September 28  2020           0.0\n",
      "..       ...        ...            ...   ...           ...\n",
      "130   after5     Friday     October 18  2019           1.0\n",
      "131  before5    Tuesday     October 01  2019           1.0\n",
      "132  before5   Thursday   September 19  2019           1.0\n",
      "133  before5     Monday      August 19  2019           1.0\n",
      "134   after5   Saturday      August 03  2019           1.0\n",
      "\n",
      "[135 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "### Days will be change to numeric values, Monday is 0, Tuesday is 1, wednesday is 2 and so on\n",
    "###Times before 5:00pm (from 7:00am to 4:59pm) will be classify as the group \"before5\" and times after 5:00pm (from 5:00pm to 12:59am) is \"after5\"\n",
    "\n",
    "# Let's start by changing for both social media data labels\n",
    "i =0\n",
    "j = 0\n",
    "\n",
    "fb_dfclass = fb_df\n",
    "fb_dfclass.rename(columns={'FacebookTime':'Time','Day':'Day','Date':'Date','Year':'Year'},inplace=True)\n",
    "fb_dfclass[\"Social Media\"] = np.zeros(len(fb_dfclass))\n",
    "insta_dfclass = insta_df\n",
    "#insta_dfclass.rename(columns={'InstagramTime':'Time','Day':'Day','Date':'Date','Year':'Year'},inplace=True)\n",
    "insta_dfclass.columns.values[0] = \"Time\"\n",
    "insta_dfclass[\"Social Media\"] = np.ones(len(insta_dfclass))\n",
    "s_dfclass = pd.concat([fb_dfclass,insta_dfclass],axis= 0,ignore_index=True)\n",
    "s_dfclass.reset_index(drop=True)\n",
    "j =0\n",
    "for index,rows in s_dfclass.iterrows():\n",
    "    fbtime = rows[0]\n",
    "    if(fbtime.find(\"am\")!= -1):\n",
    "        s_dfclass.iloc[j,0] = \"before5\"\n",
    "    elif(fbtime.find(\"pm\")!= -1): #it can be before 5:00pm like 1:00,2:00,3:00pm etc. so we have to compare\n",
    "        if(int(fbtime.split(':')[0]) < 5):\n",
    "            s_dfclass.iloc[j,0] = \"before5\" \n",
    "        else:\n",
    "            s_dfclass.iloc[j,0] = \"after5\"\n",
    "    j+=1\n",
    "\n",
    "        \n",
    "print(s_dfclass)\n",
    "s_dfclass.to_csv(\"cleanedSM.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Time        Day           Date  Year  Social Media\n",
      "0     after5   Saturday     October 28  2020           0.0\n",
      "1    before5     Sunday    October 25   2020           0.0\n",
      "2    before5    Tuesday     October 13  2020           0.0\n",
      "3     after5  Wednesday   September 30  2020           0.0\n",
      "4     after5     Monday   September 28  2020           0.0\n",
      "..       ...        ...            ...   ...           ...\n",
      "130   after5     Friday     October 18  2019           1.0\n",
      "131  before5    Tuesday     October 01  2019           1.0\n",
      "132  before5   Thursday   September 19  2019           1.0\n",
      "133  before5     Monday      August 19  2019           1.0\n",
      "134   after5   Saturday      August 03  2019           1.0\n",
      "\n",
      "[135 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "s_dfclass = pd.read_csv(\"cleanedSM.csv\")\n",
    "print(s_dfclass)\n",
    "\n",
    "days = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
    "s_days = s_dfclass.groupby(\"Day\")\n",
    "before_5 =[]\n",
    "after_5 =[]\n",
    "fbday_freq = []\n",
    "\n",
    "for day in days :\n",
    "    s_df = s_days.get_group(day)\n",
    "    time_df = s_dfclass.groupby(\"Time\")\n",
    "    #print(day_df)\n",
    "    after_5.append(len(time_df.get_group(\"after5\")))\n",
    "    before_5.append(len(time_df.get_group(\"before5\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Day  Social Media\n",
      "0      2             0\n",
      "1      3             0\n",
      "2      5             0\n",
      "3      6             0\n",
      "4      1             0\n",
      "..   ...           ...\n",
      "130    0             1\n",
      "131    5             1\n",
      "132    4             1\n",
      "133    1             1\n",
      "134    2             1\n",
      "\n",
      "[135 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "y = s_dfclass[\"Time\"]\n",
    "X = s_dfclass.drop(\"Time\", axis=1)\n",
    "X = X.drop(\"Date\",axis =1)\n",
    "X = X.drop(\"Year\",axis=1)\n",
    "#print(X)\n",
    "#print(y)\n",
    "\n",
    "##Convert data to be numerial\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(X[\"Social Media\"])\n",
    "X[\"Social Media\"] = le.transform(X[\"Social Media\"])\n",
    "le.fit(X[\"Day\"])\n",
    "X[\"Day\"] = le.transform(X[\"Day\"])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Day  Social Media\n",
      "0      2             0\n",
      "1      3             0\n",
      "2      5             0\n",
      "3      6             0\n",
      "4      1             0\n",
      "..   ...           ...\n",
      "130    0             1\n",
      "131    5             1\n",
      "132    4             1\n",
      "133    1             1\n",
      "134    2             1\n",
      "\n",
      "[135 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "y = s_dfclass[\"Time\"]\n",
    "X = s_dfclass.drop(\"Time\", axis=1)\n",
    "X = X.drop(\"Date\",axis =1)\n",
    "X = X.drop(\"Year\",axis=1)\n",
    "\n",
    "##Convert data to be numerial\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(X[\"Social Media\"])\n",
    "X[\"Social Media\"] = le.transform(X[\"Social Media\"])\n",
    "le.fit(X[\"Day\"])\n",
    "X[\"Day\"] = le.transform(X[\"Day\"])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5588235294117647\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y,random_state = 0,stratify=y)# random state for reproducility so that we will always get same data\n",
    "clf = KNeighborsClassifier(n_neighbors=3, metric=\"euclidean\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = clf.predict(X_test)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5294117647058824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=0)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_predicted_tree = tree_clf.predict(X_test)\n",
    "accuracy_tree = tree_clf.score(X_test, y_test)\n",
    "print(accuracy_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "[0.62962963 0.51851852 0.37037037 0.55555556 0.44444444] 0.5037037037037038\n",
      "0.5037037037037037\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "[0.51851852 0.2962963  0.51851852 0.55555556 0.44444444] 0.4666666666666666\n",
      "0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for model in [clf, tree_clf]:\n",
    "    print(type(model))\n",
    "    accuracies = cross_val_score(model, X, y, cv=5)\n",
    "    print(accuracies, accuracies.mean())\n",
    "    y_predictions = cross_val_predict(model, X, y, cv=5) # GS: look into random_state for this one\n",
    "    # better estimate of accuracy\n",
    "    accuracy = accuracy_score(y, y_predictions)\n",
    "    print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
